图像序列的层次结构: I/P/B帧和GOP。图像的内部层次结构是Slice，其实就是“片”的概念，
一帧图像可以划分成一个或多个 Slice，而一个 Slice 包含多个宏块，且一个宏块又可以划分成多个不同尺寸的子块

大概就是类似下面这样的结构图：

![image](https://github.com/dwjlw1314/DWJ-PROJECT/raw/master/PictureSource/8.2.1.png)

H.264 码流有两种格式：一种是 Annexb 格式; 一种是 MP4 格式。这两种格式差别不大

下面使用 Annexb 格式来了解 H264 码流结构

H.264 的功能分为两层，即视频编码层（VCL）和网络提取层（NAL，Network Abstraction Layer）

VCL：包括核心压缩引擎和块，宏块和片的语法级别定义，目标是尽可能地独立于网络进行高效的编码

NAL: 负责将VCL产生的比特字符串数据进行封装，适配到各种网络环境中传输

H.264原始码流是一个一个的NALU组成的，每个NALU之间都使用start code（起始码）分隔
```
start code为00 00 00 01 或者 00 00 01

00 00 00 01为SPS或PPS的起始码

00 00 01是其他NALU的起始码
```

NALU由一个字节的头部信息（NAL header）和一个原始字节序列负荷（RBSP）组成，其中NAL Header位描述如下：
```
bit[7]：必须为0

bit[5-6]：标记该NALU的重要性

bit[0-4]：NALU单元的类型
```

常见的 NALU 里的 NALU Header：

![image](https://github.com/dwjlw1314/DWJ-PROJECT/raw/master/PictureSource/8.2.3.png)

下图为NAL Header的具体定义：

![image](https://github.com/dwjlw1314/DWJ-PROJECT/raw/master/PictureSource/8.2.2.png)

类型为 7、8 的 NAL 单元中分别包含了两个重要的解码图像参数集：一个是 SPS（序列参数集）；一个是 PPS（图像参数集）

SPS 主要包含的是图像的宽、高、YUV 格式和位深等基本信息；PPS 则主要包含熵编码类型、基础 QP 和最大参考帧数量等基本编码信息

其中 NALU Header 的 Type 字段只区分了 IDR Slice 和非 IDR Slice，其他Slice则需要继续解析 Slice Header 中的 Slice Type 字段得到

NALU是由 SPS、PPS、SEI、IDR_SLICE、SLICE，并且这些NALU组成了一个序列，一个H264包含一个或者多个序列

![image](https://github.com/dwjlw1314/DWJ-PROJECT/raw/master/PictureSource/8.2.5.png)

![image](https://github.com/dwjlw1314/DWJ-PROJECT/raw/master/PictureSource/8.2.8.png)

根据码流中不同的数据类型，H.264标准中共定义了5总Slice类型
```
I slice:   帧内编码的slice
P slice:   单向帧间编码的slice
B slice:   双向帧间编码的slice
SI slice:  切换Islice，用于扩展档次中码流切换使用
SP slice:  切换Pslice，用于扩展档次中码流切换使用
```

假设FPS=30的情况，一个squence包含一个SPS、一个PPS、一个SEI、一个IDR（非参考帧）、29个PDR（参考帧）

一般SPS和PPS的NAL Unit通常位于整个码流的起始位置。特殊情况也会在码流中间出现这两种结构，主要原因可能是：

```
1. 解码器需要在码流中间开始解码
2. 编码器在编码的过程中改变了码流的参数（如图像分辨率等）
```

SPS中保存了一组编码视频序列(Coded video sequence)的全局参数，谓的编码视频序列即原始视频的一帧一帧的像素数据经过编码之后的结构组成的序列

![image](https://github.com/dwjlw1314/DWJ-PROJECT/raw/master/PictureSource/8.2.4.png)

```
profile_idc：
  标识当前H.264码流的profile。我们知道，H.264中定义了三种常用的档次profile：
  基准档次：baseline profile;
  主要档次：main profile;
  扩展档次：extended profile;

  在H.264的SPS中，第一个字节表示profile_idc，根据profile_idc的值可以确定码流符合哪一种档次。判断规律为：
  profile_idc = 66 → baseline profile;
  profile_idc = 77 → main profile;
  profile_idc = 88 → extended profile;

  在新版的标准中，还包括了High、High 10、High 4:2:2、High 4:4:4、High 10 Intra、High 4:2:2 Intra、High 4:4:4 Intra、CAVLC 4:4:4 Intra等，每一种都由不同的profile_idc表示

  另外，constraint_set0_flag ~ constraint_set5_flag是在编码的档次方面对码流增加的其他一些额外限制性条件

  在我们实验码流中，profile_idc = 0x42 = 66，因此码流的档次为baseline profile

level_idc
  标识当前码流的Level。编码的Level定义了某种条件下的最大视频分辨率、最大视频帧率等参数，码流所遵从的level由level_idc指定

  当前码流中，level_idc = 0x1e = 30，因此码流的级别为3

seq_parameter_set_id
  表示当前的序列参数集的id。通过该id值，图像参数集pps可以引用其代表的sps中的参数

log2_max_frame_num_minus4
  用于计算MaxFrameNum的值。计算公式为MaxFrameNum = 2^(log2_max_frame_num_minus4 + 4)
  MaxFrameNum是frame_num的上限值，frame_num是图像序号的一种表示方法，在帧间编码中常用作一种参考帧标记的手段

pic_order_cnt_type
  表示解码picture order count(POC)的方法。POC是另一种计量图像序号的方式，与frame_num有着不同的计算方法。该语法元素的取值为0、1或2

log2_max_pic_order_cnt_lsb_minus4
  用于计算MaxPicOrderCntLsb的值，该值表示POC的上限。计算方法为MaxPicOrderCntLsb = 2^(log2_max_pic_order_cnt_lsb_minus4 + 4)

max_num_ref_frames
  用于表示参考帧的最大数目

gaps_in_frame_num_value_allowed_flag
  标识位，说明frame_num中是否允许不连续的值

pic_width_in_mbs_minus1
  用于计算图像的宽度。单位为宏块个数，因此图像的实际宽度为: frame_width = 16 × (pic_width_in_mbs_minus1 + 1);

pic_height_in_map_units_minus1
  使用PicHeightInMapUnits来度量视频中一帧图像的高度。PicHeightInMapUnits并非图像明确的以像素或宏块为单位的高度，而需要考虑该宏块是帧编码或场编码
  PicHeightInMapUnits的计算方式为：PicHeightInMapUnits = pic_height_in_map_units_minus1 + 1;

frame_mbs_only_flag
  标识位，说明宏块的编码方式。当该标识位为0时，宏块可能为帧编码或场编码；该标识位为1时，所有宏块都采用帧编码。根据该标识位取值不同，PicHeightInMapUnits的含义也不同，
  为0时表示一场数据按宏块计算的高度，为1时表示一帧数据按宏块计算的高度
  按照宏块计算的图像实际高度FrameHeightInMbs的计算方法为：FrameHeightInMbs = ( 2 − frame_mbs_only_flag ) * PicHeightInMapUnits

mb_adaptive_frame_field_flag
  标识位，说明是否采用了宏块级的帧场自适应编码。当该标识位为0时，不存在帧编码和场编码之间的切换；当标识位为1时，宏块可能在帧编码和场编码模式之间进行选择

direct_8x8_inference_flag
  标识位，用于B_Skip、B_Direct模式运动矢量的推导计算

frame_cropping_flag
  标识位，说明是否需要对输出的图像帧进行裁剪

vui_parameters_present_flag
  标识位，说明SPS中是否存在VUI信息
```

PPS NAL Unit的nal_unit_type值为8；而在封装格式中，PPS通常与SPS一起，保存在视频文件的文件头中

![image](https://github.com/dwjlw1314/DWJ-PROJECT/raw/master/PictureSource/8.2.7.png)

```
pic_parameter_set_id
  表示当前PPS的id。某个PPS在码流中会被相应的slice引用，slice引用PPS的方式就是在Slice header中保存PPS的id值。该值的取值范围为[0,255]

seq_parameter_set_id
  表示当前PPS所引用的激活的SPS的id。通过这种方式，PPS中也可以取到对应SPS中的参数。该值的取值范围为[0,31]

entropy_coding_mode_flag
  熵编码模式标识，该标识位表示码流中熵编码/解码选择的算法。对于部分语法元素，在不同的编码配置下，选择的熵编码方式不同。例如在一个宏块语法元素中，宏块类型mb_type的语法元素描述符为“ue(v) | ae(v)”，在baseline profile等设置下采用指数哥伦布编码，在main profile等设置下采用CABAC编码。标识位entropy_coding_mode_flag的作用就是控制这种算法选择。当该值为0时，选择左边的算法，通常为指数哥伦布编码或者CAVLC；当该值为1时，选择右边的算法，通常为CABAC

bottom_field_pic_order_in_frame_present_flag
  标识位，用于表示另外条带头中的两个语法元素delta_pic_order_cnt_bottom和delta_pic_order_cn是否存在的标识。这两个语法元素表示了某一帧的底场的POC的计算方法

num_slice_groups_minus1
  表示某一帧中slice group的个数。当该值为0时，一帧中所有的slice都属于一个slice group。slice group是一帧中宏块的组合方式，定义在协议文档的3.141部分

num_ref_idx_l0_default_active_minus1、num_ref_idx_l0_default_active_minus1
  表示当Slice Header中的num_ref_idx_active_override_flag标识位为0时，P/SP/B slice的语法元素num_ref_idx_l0_active_minus1和num_ref_idx_l1_active_minus1的默认值

weighted_pred_flag
  标识位，表示在P/SP slice中是否开启加权预测

weighted_bipred_idc
  表示在B Slice中加权预测的方法，取值范围为[0,2]。0表示默认加权预测，1表示显式加权预测，2表示隐式加权预测

pic_init_qp_minus26和pic_init_qs_minus26
  表示初始的量化参数。实际的量化参数由该参数、slice header中的slice_qp_delta/slice_qs_delta计算得到

chroma_qp_index_offset
  用于计算色度分量的量化参数，取值范围为[-12,12]

deblocking_filter_control_present_flag
  标识位，用于表示Slice header中是否存在用于去块滤波器控制的信息。当该标志位为1时，slice header中包含去块滤波相应的信息；当该标识位为0时，slice header中没有相应的信息

constrained_intra_pred_flag
  若该标识为1，表示I宏块在进行帧内预测时只能使用来自I和SI类型宏块的信息；若该标识位0，表示I宏块可以使用来自Inter类型宏块的信息

redundant_pic_cnt_present_flag
  标识位，用于表示Slice header中是否存在redundant_pic_cnt语法元素。当该标志位为1时，slice header中包含redundant_pic_cnt；当该标识位为0时，slice header中没有相应的信息
```

GOP就是一段时间内变化不大的图像集。GOP结构一般有两个数字，如M=3，N=12。M指定I帧和P帧之间的距离，N指定两个I帧之间的距离。GOP结构为：IBBPBBPBBPBBI

在一个GOP内I frame解码不依赖任何的其它帧，p frame解码则依赖前面的I frame或P frame，B frame解码依赖前最近的一个I frame或P frame 及其后最近的一个P frame

![image](https://github.com/dwjlw1314/DWJ-PROJECT/raw/master/PictureSource/8.2.6.png)

一个宏块 = 一个16*16的亮度像素 + 一个8×8Cb + 一个8×8Cr彩色像素块组成

YCbCr 是属于 YUV 家族的一员,在YCbCr 中 Y 是指亮度分量，Cb 指蓝色色度分量，而 Cr 指红色色度分量

判断 Slice Header.first_mb_in_slice=0 使用方法：slice_header[0] & 0x80 == 1

参考: H.264官方中文档.pdf
